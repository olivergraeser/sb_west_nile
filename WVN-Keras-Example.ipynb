{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_count = 4\n",
    "seed = 1337\n",
    "\n",
    "model_dict = {\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    'optimizer': 'adadelta',\n",
    "    'layers': [{'nodecount': 32, 'activation': 'relu', 'dropout': 0.5},\n",
    "               {'nodecount': 32, 'activation': 'relu', 'dropout': 0.5}],\n",
    "    'dimension_out': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('west_nile/input/train.csv')\n",
    "#train_df.info()\n",
    "test_df = pd.read_csv('west_nile/input/test.csv')\n",
    "#test_df.info()\n",
    "cnt_train_df = train_df.groupby(['Date', 'Species', 'Trap']).count()\n",
    "#cnt_train_df[cnt_train_df['NumMosquitos'] > 1]\n",
    "weather_df = pd.read_csv('west_nile/input/weather.csv')\n",
    "weather_df = weather_df[weather_df['Station'] == 2]\n",
    "spray_df = pd.read_csv('west_nile/input/spray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_weather_df = pd.merge(left=train_df, right=weather_df, how='inner', left_on=['Date'], right_on=['Date'])\n",
    "train_with_weather_df['month'] = train_with_weather_df.apply(lambda _: datetime.strptime(_['Date'], '%Y-%m-%d').date().month, axis=1)\n",
    "train_with_weather_df['week'] = train_with_weather_df.apply(lambda _: _['month'] * 4 + datetime.strptime(_['Date'], '%Y-%m-%d').date().day / 7, axis=1)\n",
    "train_target_df = train_with_weather_df[['WnvPresent']]\n",
    "train_init_df = train_with_weather_df[['month', 'week', 'Latitude', 'Longitude', 'Tmax', 'Tmin', \n",
    "                                               'Tavg', 'DewPoint', 'WetBulb', 'StnPressure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "shuffle = np.arange(len(train_with_weather_df))\n",
    "np.random.shuffle(shuffle)\n",
    "train_target_df = train_target_df.iloc[shuffle]\n",
    "train_init_df = train_init_df.iloc[shuffle]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_init_df)\n",
    "train_init_array = scaler.transform(train_init_df)\n",
    "train_target_id = np.asarray(train_target_df)\n",
    "train_target_array = np_utils.to_categorical(train_target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_dict):\n",
    "    model = Sequential()\n",
    "    input_dim = model_dict['dimension_input']\n",
    "    for layer in model_dict['layers']:\n",
    "        model.add(Dense(layer['nodecount'], input_dim=input_dim))\n",
    "        model.add(Activation(layer['activation']))\n",
    "        model.add(Dropout(layer['dropout']))\n",
    "        input_dim = layer['nodecount']\n",
    "\n",
    "    model.add(Dense(model_dict['dimension_output']))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=model_dict['loss'], optimizer=model_dict['optimizer'])\n",
    "    return model\n",
    "\n",
    "model_dict['dimension_input'] = train_init_array.shape[1]\n",
    "model_dict['dimension_output'] = train_target_array.shape[1] \n",
    "model = build_model(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Fold 0\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.790618955513\n",
      "------------------------------------------------------------\n",
      "Fold 1\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.793178973717\n",
      "------------------------------------------------------------\n",
      "Fold 2\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.795925527496\n",
      "------------------------------------------------------------\n",
      "Fold 3\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.762509666057\n",
      "Average ROC: 0.785558280696\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(len(train_target_id), fold_count)\n",
    "mean_auroc = 0.\n",
    "\n",
    "for i, (train, valid) in enumerate(folds):\n",
    "    print('---'*20)\n",
    "    print('Fold', i)\n",
    "    print('---'*20)\n",
    "    X_train = train_init_array[train]\n",
    "    X_valid = train_init_array[valid]\n",
    "    Y_train = train_target_array[train]\n",
    "    Y_valid = train_target_array[valid]\n",
    "    y_valid = train_target_id[valid]\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = build_model(model_dict)\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=16, validation_data=(X_valid, Y_valid), verbose=0)\n",
    "    valid_preds = model.predict_proba(X_valid, verbose=0)\n",
    "    valid_preds_transform = valid_preds[:, 1]\n",
    "    roc = metrics.roc_auc_score(y_valid, valid_preds_transform)\n",
    "    print(\"ROC:\", roc)\n",
    "    mean_auroc += roc\n",
    "\n",
    "print('Average ROC:', mean_auroc/fold_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = csv.reader(open(\"./west_nile/input/test.csv\"))\n",
    "head = fi.__next__()\n",
    "indexes = dict([(head[i], i) for i in range(len(head))])\n",
    "rows = []\n",
    "ids = []\n",
    "for line in fi:\n",
    "    rows.append(process_line(line, indexes, weather_dic, weather_indexes))\n",
    "    ids.append(line[0])\n",
    "X_test = np.array(rows)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "preds = model.predict_proba(X_test, verbose=0)\n",
    "\n",
    "fo = csv.writer(open(\"keras-nn.csv\", \"w\"), lineterminator=\"\\n\")\n",
    "fo.writerow([\"Id\",\"WnvPresent\"])\n",
    "\n",
    "for i, item in enumerate(ids):\n",
    "    fo.writerow([ids[i], preds[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
