{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import date, datetime\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from utils import read_basic_dataset\n",
    "\n",
    "from features import get_month_virus_share, create_trap_distance_matrix, get_nearest_trap, get_nearest_trap_list, \\\n",
    "    add_multirows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_count = 5\n",
    "seed = 1337\n",
    "train_verbose = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Basic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features, training_target, test_features = read_basic_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trap_records = pd.concat([training_features[['Trap', 'Latitude', 'Longitude']], \n",
    "                          test_features[['Trap', 'Latitude', 'Longitude']]])\n",
    "trap_distance_matrix = create_trap_distance_matrix(trap_records)\n",
    "#trap_distance_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Address</th>\n",
       "      <th>Species</th>\n",
       "      <th>Block</th>\n",
       "      <th>Street</th>\n",
       "      <th>Trap</th>\n",
       "      <th>AddressNumberAndStreet</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>10dtmin_min</th>\n",
       "      <th>10dtavg_avg</th>\n",
       "      <th>10dtavg_max</th>\n",
       "      <th>10dtavg_min</th>\n",
       "      <th>10dpcp_tot</th>\n",
       "      <th>10ddwp_avg</th>\n",
       "      <th>10dprs_avg</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>71.090909</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>60.363636</td>\n",
       "      <td>29.105455</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>71.090909</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>60.363636</td>\n",
       "      <td>29.105455</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX PIPIENS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>71.090909</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>60.363636</td>\n",
       "      <td>29.105455</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX SALINARIUS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>71.090909</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>60.363636</td>\n",
       "      <td>29.105455</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4100 North Oak Park Avenue, Chicago, IL 60634,...</td>\n",
       "      <td>CULEX TERRITANS</td>\n",
       "      <td>41</td>\n",
       "      <td>N OAK PARK AVE</td>\n",
       "      <td>T002</td>\n",
       "      <td>4100  N OAK PARK AVE, Chicago, IL</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>71.090909</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>60.363636</td>\n",
       "      <td>29.105455</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        Date                                            Address  \\\n",
       "0   1  2008-06-11  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "1   2  2008-06-11  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "2   3  2008-06-11  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "3   4  2008-06-11  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "4   5  2008-06-11  4100 North Oak Park Avenue, Chicago, IL 60634,...   \n",
       "\n",
       "                  Species  Block           Street  Trap  \\\n",
       "0  CULEX PIPIENS/RESTUANS     41   N OAK PARK AVE  T002   \n",
       "1          CULEX RESTUANS     41   N OAK PARK AVE  T002   \n",
       "2           CULEX PIPIENS     41   N OAK PARK AVE  T002   \n",
       "3        CULEX SALINARIUS     41   N OAK PARK AVE  T002   \n",
       "4         CULEX TERRITANS     41   N OAK PARK AVE  T002   \n",
       "\n",
       "              AddressNumberAndStreet  Latitude  Longitude ...   10dtmin_min  \\\n",
       "0  4100  N OAK PARK AVE, Chicago, IL  41.95469 -87.800991 ...            53   \n",
       "1  4100  N OAK PARK AVE, Chicago, IL  41.95469 -87.800991 ...            53   \n",
       "2  4100  N OAK PARK AVE, Chicago, IL  41.95469 -87.800991 ...            53   \n",
       "3  4100  N OAK PARK AVE, Chicago, IL  41.95469 -87.800991 ...            53   \n",
       "4  4100  N OAK PARK AVE, Chicago, IL  41.95469 -87.800991 ...            53   \n",
       "\n",
       "   10dtavg_avg  10dtavg_max  10dtavg_min  10dpcp_tot  10ddwp_avg 10dprs_avg  \\\n",
       "0    71.090909         80.0         62.0       2.654   60.363636  29.105455   \n",
       "1    71.090909         80.0         62.0       2.654   60.363636  29.105455   \n",
       "2    71.090909         80.0         62.0       2.654   60.363636  29.105455   \n",
       "3    71.090909         80.0         62.0       2.654   60.363636  29.105455   \n",
       "4    71.090909         80.0         62.0       2.654   60.363636  29.105455   \n",
       "\n",
       "   year month week  \n",
       "0  2008     6   24  \n",
       "1  2008     6   24  \n",
       "2  2008     6   24  \n",
       "3  2008     6   24  \n",
       "4  2008     6   24  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virus_per_trap_species, virus_per_trap, virus_per_species_overall = get_month_virus_share(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_rate = training_features['WnvPresent'].sum()/training_features['NumMosquitos'].sum()\n",
    "def virusshare_best_source(row):\n",
    "    if not pd.isnull(row['virusshare_ts']):\n",
    "        return row['virusshare_ts']\n",
    "    elif not (pd.isnull(row['virusshare_t']) or pd.isnull(row['species_virus'])):\n",
    "        return row['virusshare_t'] * row['species_virus'] / overall_rate\n",
    "    elif not pd.isnull(row['species_virus']):\n",
    "        return row['species_virus']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "training_features = pd.merge(how='left', left=training_features, right=virus_per_trap_species, \n",
    "                             left_on=['month', 'Trap', 'Species'], right_index=True)\n",
    "training_features['virusshare'] = training_features.apply(lambda _: _['virusshare_ts'], axis=1)\n",
    "training_features['species_virus'] = training_features.Species.\\\n",
    "    apply(lambda _: virus_per_species_overall.loc[_]['virusshare_s'] if _ in virus_per_species_overall.index else -1)\n",
    "#cols_to_use = test_features.columns.difference(virus_share_df.columns)\n",
    "test_features = pd.merge(how='left', left=test_features, right=virus_per_trap_species, \n",
    "                             left_on=['month', 'Trap', 'Species'], right_index=True)\n",
    "test_features = pd.merge(how='left', left=test_features, right=virus_per_trap, \n",
    "                             left_on=['month', 'Trap'], right_index=True)\n",
    "test_features['species_virus'] = test_features.Species.\\\n",
    "    apply(lambda _: virus_per_species_overall.loc[_]['virusshare_s'] \n",
    "          if _ in virus_per_species_overall.index else -1)\n",
    "test_features['virusshare'] = test_features.apply(virusshare_best_source, axis=1)\n",
    "\n",
    "#test_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = add_multirows(training_features)\n",
    "test_features = add_multirows(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature NumMosquitos not among testing features\n",
      "Feature WnvPresent not among testing features\n",
      "Feature Id not among training features\n",
      "Feature virusshare_t not among training features\n",
      "Feature location_distance not among training features\n",
      "Feature location_distance not among testing features\n"
     ]
    }
   ],
   "source": [
    "keep_features = ['week', 'Latitude', 'Longitude', \n",
    "                 'Tmax', 'Tmin', 'Tavg', 'DewPoint', 'StnPressure', 'PrecipTotal',\n",
    "                 '', '10dtmin_min', '10dtavg_avg', '10dpcp_tot', '10ddwp_avg', '10dprs_avg']\n",
    "drop_features = ['AddressAccuracy','AddressNumberAndStreet','Address', 'Block', 'Date', \n",
    "                 'Heat', 'Cool', 'Sunrise', 'Sunset','Depth','Water1','SeaLevel', 'SnowFall', 'CodeSum', \n",
    "                 'Depart', 'WetBulb', 'ResultSpeed', 'ResultDir', 'AvgSpeed', \n",
    "                 'month', 'Species', 'station','Street', 'Trap', 'Station', 'ddate', 'year',\n",
    "                 'NumMosquitos', 'WnvPresent', 'Id',\n",
    "                 'virusshare_ts', 'virusshare_t', 'location_distance',\n",
    "                 #'10dtmax_max',\n",
    "                 '10dtmax_min', \n",
    "                 '10dtmax_avg', \n",
    "                 '10dtavg_max', \n",
    "                 #'10dtavg_avg', \n",
    "                 #'10dtavg_min', \n",
    "                 '10dtmin_max', \n",
    "                 '10dtmin_avg',\n",
    "                 #'10dtmin_min', \n",
    "                 #'10dpcp_tot', \n",
    "                 #'10ddwp_avg', \n",
    "                 #'10dprs_avg'\n",
    "                ]\n",
    "training_features_input = training_features.copy()\n",
    "test_features_input = test_features.copy()\n",
    "for drop_feature in drop_features:\n",
    "    if drop_feature in training_features_input.columns:\n",
    "        training_features_input = training_features_input.drop([drop_feature], axis=1)\n",
    "    else: \n",
    "        print('Feature {} not among training features'.format(drop_feature))\n",
    "    if drop_feature in test_features_input.columns:\n",
    "        test_features_input = test_features_input.drop([drop_feature], axis=1)\n",
    "    else: \n",
    "        print('Feature {} not among testing features'.format(drop_feature))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "shuffle = np.arange(len(training_features_input))\n",
    "np.random.shuffle(shuffle)\n",
    "training_target_input = training_target.iloc[shuffle]\n",
    "training_features_input = training_features_input.iloc[shuffle]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(training_features_input)\n",
    "training_feature_array = scaler.transform(training_features_input)\n",
    "training_target_array = np.asarray(training_target_input)\n",
    "test_feature_array = scaler.transform(test_features_input.fillna(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(fold_cnt, feature_array, target_array, model_generator, fitting_function):\n",
    "    folds = KFold(len(target_array), fold_count)\n",
    "    mean_auroc_valid = 0.\n",
    "    mean_auroc_train = 0\n",
    "    target_array_categorical = np_utils.to_categorical(target_array)\n",
    "    trained_models = list()\n",
    "    for i, (train, valid) in enumerate(folds):\n",
    "        print('Fold', i)\n",
    "        X_train = feature_array[train]\n",
    "        X_valid = feature_array[valid]\n",
    "        Y_train = target_array_categorical[train]\n",
    "        y_train = target_array[train]\n",
    "        Y_valid = target_array_categorical[valid]\n",
    "        y_valid = target_array[valid]\n",
    "        foldmodel = model_generator()\n",
    "        train_and_valid_data = (X_train, Y_train, y_train, X_valid, Y_valid, y_valid)\n",
    "        fitting_function(foldmodel, train_and_valid_data)\n",
    "        trained_models.append(foldmodel)\n",
    "        valid_preds = foldmodel.predict_proba(X_valid)\n",
    "        training_preds = foldmodel.predict_proba(X_train)\n",
    "        roc_valid = metrics.roc_auc_score(y_valid, valid_preds[:, 1])\n",
    "        roc_train = metrics.roc_auc_score(y_train, training_preds[:, 1])\n",
    "        #print(\"ROC: {} training, {} validation\".format(roc_train, roc_valid))\n",
    "        mean_auroc_train += roc_train\n",
    "        mean_auroc_valid += roc_valid\n",
    "            \n",
    "    print('Average ROC:', mean_auroc_train/fold_count, mean_auroc_valid/fold_count)\n",
    "    return trained_models\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Average ROC: 0.964825085173 0.916808799635\n"
     ]
    }
   ],
   "source": [
    "#xgb = XGBClassifier()\n",
    "#xgb.fit(training_feature_array, training_target_array.ravel())\n",
    "#xgb.predict_proba(np.array(test_feature_array))\n",
    "\n",
    "def xgb_model_builder(xgb_model_dict=None):\n",
    "    if not xgb_model_dict:\n",
    "        xgb_model_dict={'n_estimators': 300,\n",
    "                        'max_depth': 3,\n",
    "                        'reg_alpha':0.01,\n",
    "                        'seed':seed}\n",
    "    return XGBClassifier(**xgb_model_dict)\n",
    "\n",
    "def xgb_fitting_function(xgb_model, tvd):\n",
    "    xgb_model.fit(tvd[0], tvd[2].ravel())\n",
    "    \n",
    "xgbms = train_model(fold_count, training_feature_array, training_target_array, xgb_model_builder, xgb_fitting_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01533597,  0.00656668,  0.01593937, ...,  0.00010511,\n",
       "        0.00010511,  0.00010511], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_prediction_array = [xgb.predict_proba(np.nan_to_num(test_feature_array))[:,1] \n",
    "                        for xgb in xgbms]\n",
    "bagged_xgb_prediction = np.mean(np.array(xgb_prediction_array), axis=0)\n",
    "bagged_xgb_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>0.120278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>0.110495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tmax</th>\n",
       "      <td>0.043694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tmin</th>\n",
       "      <td>0.013307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tavg</th>\n",
       "      <td>0.025495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPoint</th>\n",
       "      <td>0.023814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecipTotal</th>\n",
       "      <td>0.017491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StnPressure</th>\n",
       "      <td>0.032762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dtmax_max</th>\n",
       "      <td>0.031814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dtmin_min</th>\n",
       "      <td>0.037252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dtavg_avg</th>\n",
       "      <td>0.021726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dtavg_min</th>\n",
       "      <td>0.029026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dpcp_tot</th>\n",
       "      <td>0.057805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10ddwp_avg</th>\n",
       "      <td>0.063354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10dprs_avg</th>\n",
       "      <td>0.056493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.025070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species_virus</th>\n",
       "      <td>0.198002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virusshare</th>\n",
       "      <td>0.021970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rowcount</th>\n",
       "      <td>0.070152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Importance\n",
       "Feature                  \n",
       "Latitude         0.120278\n",
       "Longitude        0.110495\n",
       "Tmax             0.043694\n",
       "Tmin             0.013307\n",
       "Tavg             0.025495\n",
       "DewPoint         0.023814\n",
       "PrecipTotal      0.017491\n",
       "StnPressure      0.032762\n",
       "10dtmax_max      0.031814\n",
       "10dtmin_min      0.037252\n",
       "10dtavg_avg      0.021726\n",
       "10dtavg_min      0.029026\n",
       "10dpcp_tot       0.057805\n",
       "10ddwp_avg       0.063354\n",
       "10dprs_avg       0.056493\n",
       "week             0.025070\n",
       "species_virus    0.198002\n",
       "virusshare       0.021970\n",
       "rowcount         0.070152"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_array = np.mean(np.array([xgb.feature_importances_ for xgb in xgbms]), axis=0)\n",
    "feature_importance_df = pd.DataFrame(list(zip(test_features_input.columns, feature_importance_array)))\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "feature_importance_df.set_index('Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    'optimizer': 'adadelta',\n",
    "    'layers': [{'nodecount': 30, 'activation': 'relu', 'dropout': 0.5},\n",
    "               {'nodecount': 20, 'activation': 'relu', 'dropout': 0.25},\n",
    "               {'nodecount': 10, 'activation': 'relu', 'dropout': 0.125}],\n",
    "    'dimension_out': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "6112/8404 [====================>.........] - ETA: 0sFold 1\n",
      "6208/8405 [=====================>........] - ETA: 0sFold 2\n",
      "8405/8405 [==============================] - 0s     \n",
      "Fold 3\n",
      "7968/8405 [===========================>..] - ETA: 0sFold 4\n",
      "5888/8405 [====================>.........] - ETA: 0sAverage ROC: 0.906141456636 0.894112187451\n"
     ]
    }
   ],
   "source": [
    "def build_model(model_dict):\n",
    "    model = Sequential()\n",
    "    input_dim = model_dict['dimension_input']\n",
    "    for layer in model_dict['layers']:\n",
    "        model.add(Dense(layer['nodecount'], input_dim=input_dim))\n",
    "        model.add(Activation(layer['activation']))\n",
    "        model.add(Dropout(layer['dropout']))\n",
    "        input_dim = layer['nodecount']\n",
    "\n",
    "    model.add(Dense(model_dict['dimension_output']))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=model_dict['loss'], optimizer=model_dict['optimizer'])\n",
    "    return model\n",
    "\n",
    "model_dict['dimension_input'] = training_feature_array.shape[1]\n",
    "model_dict['dimension_output'] = len(np.unique(training_target_array))\n",
    "\n",
    "def keras_model_builder():\n",
    "    return build_model(model_dict)\n",
    "def keras_fit(keras_model, tvd):\n",
    "    keras_model.fit(tvd[0], tvd[1], epochs=50, batch_size=32, validation_data=(tvd[3], tvd[4]), verbose=train_verbose)\n",
    "\n",
    "fnn = keras_model_builder()\n",
    "fnnms = train_model(fold_count, training_feature_array, training_target_array, keras_model_builder, keras_fit)\n",
    "#keras_fit(fnn, )\n",
    "#FNN = train_model(4, train_init_array, train_target_id, keras_model_builder, keras_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116288/116293 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "fnn_prediction_array = [fnn.predict_proba(np.nan_to_num(test_feature_array))[:,1] for fnn in fnnms]\n",
    "bagged_fnn_prediction = np.mean(np.array(fnn_prediction_array), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features['WnvPresent'] = bagged_xgb_prediction\n",
    "export_df = test_features[['Id', 'WnvPresent']]\n",
    "export_df.to_csv('multirow.csv', index=False , quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
